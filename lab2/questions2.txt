Question 1: What is the advantage of using Vertex Arrays above immediate 
mode rendering?
Immediate mode does a lot of functions calls, which is very inefficient.
Vertex arrays reach the same result, but use only a single function call.
So, using Vertex arrays is faster than using immediate mode rendering.

Question 2: What are uvec and vvec in the Surfel structure? What properties of 
the splat do they represent?
uvec and vvec are the vectors that determine the orientation and size of a splat. 

Question 3: On the slide, it is not shown how to compute peye. This
is the position in of the point in eye (view)-space. What matrix should be
used to transform a position from object-space to eye-space?
Modelview matrix. If the MVP matrix is used then the points end up in clip space

Question 4: Does it matter whether we pass the surfel color to the
vertex shader in a texture coordinate (glTexCoord...) or as the vertex color
(glColor...)? Why (not)?
Using color makes sure that CG knows what variable to use as color.
With textCoord, openGL does not know this. So OpenGL has to be told which variable represents a color.

Question 5: What matrix should you use to transform the u and v vectors? Is
it different from the matrix you would use to transform a normal? Why (not)?
The ModelView matrix is used to transform the u and v vectors while to transform normals the inverse-transpose of the ModelView matrix is used.  This is due to that when an object is transformed, the normals should change orientation because the shape of the object changes. However, the u and v vectors are bound to the point and thus should stay in place. That is why a different matrix must be used.

Question 6: Why would we want to move as much computations as
possible from the fragment program to the vertex program, or even from the
vertex program to the application?
Because a computation in the fragment program is done for every fragment ('potential-pixel'), which are a lot.
The vertex program only performs computations at each vertex, which are less than the fragments.
The application performs computations on every frame, or only once. 

Question 7: Does it matter which values the outputs have when a
fragment is discarded?
No, as soon a fragment is discarded, the data is not processed through the remaining part of the pipeline.

Question 8: What is the difference between a texture and a render buffer?
They both store pixel data but textures can be bound to shaders and rendered with but a renderbuffer can only be bound to an framebuffer object. However, because renderbuffer objects give hints about the data they store it can sometimes be stored more effective.

Question 9: Why must depth write be disabled when blending the fragments?
If depth writing is not disabled then the previous obtained depth information is overwritten in the blending pass. 
